{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem Resampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for repeatable results for random sampling\n",
    "#np.random.seed(1213145)\n",
    "# this does the resampling for sample distributions\n",
    "def CLM_resampler(distribution, sample_size, num_samples):\n",
    "    np.random.seed(1213145)\n",
    "    sample_means = np.zeros(num_samples)\n",
    "    pop_std = distribution.std()\n",
    "    for idx, num in enumerate(range(num_samples)):\n",
    "        sample = np.random.choice(distribution, size=sample_size, replace=True)\n",
    "        sample_means[idx] = sample.mean()\n",
    "    return sample_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem Resampling Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_limit_theorem_mean(distribution, sample_size, num_samples):  ## distribution must be an array (df.CARRIER_DELAY)\n",
    "    sample_means = np.zeros(num_samples)\n",
    "    pop_std = distribution.std()\n",
    "    for idx, num in enumerate(range(num_samples)):\n",
    "        sample = np.random.choice(distribution, size=sample_size, replace=True)\n",
    "        sample_means[idx] = sample.mean()\n",
    "    return sample_means.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_limit_theorem_plotter(distribution, sample_size, num_samples):\n",
    "    sample_means = np.zeros(num_samples)\n",
    "    pop_std = distribution.std()\n",
    "    for idx, num in enumerate(range(num_samples)):\n",
    "        sample = np.random.choice(distribution, size=sample_size, replace=True)\n",
    "        sample_means[idx] = sample.mean()\n",
    "    sns.set_style(\"ticks\", {\"xtick.major.size\":50, \"ytick.major.size\":50})\n",
    "    ax = sns.distplot(sample_means, bins=50, kde=True)\n",
    "    title = 'Sample Distribution n = {} and number of samples = {}, std error = {}'.format(\n",
    "        sample_size, num_samples, round((pop_std/num_samples), ndigits = 3))\n",
    "    ax.set_xlabel('Sample Mean Delay Times (minutes)', fontdict={'fontsize' : 15})\n",
    "    print('mean = {}'.format(sample_means.mean()))\n",
    "    plt.title(title, {'fontsize': 20,\n",
    "        'fontweight' : 12,\n",
    "        'verticalalignment': 'baseline'})\n",
    "    return sample_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportion Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates proportion of delayed or cancelled flights given our dataframe - very narrow scope for this function, easy to break\n",
    "def calc_prop(df, prop_type):\n",
    "    if prop_type == 'cancelled':\n",
    "        df_can = df.loc[(df.CANCELLATION_CODE=='A'),:].shape[0]\n",
    "        df_nobs_can = df.shape[0]\n",
    "        df_proportion_can = df_can/df_nobs_can\n",
    "        return df_proportion_can, df_nobs_can, df_can\n",
    "    elif prop_type == 'delayed':\n",
    "        df_del = df.loc[((df.CARRIER_DELAY>0) & (df.CANCELLED==0)),:].shape[0]\n",
    "        df_nobs_del = df.loc[(df.CANCELLED==0),:].shape[0]\n",
    "        df_proportion_del = df_del/df_nobs_del\n",
    "        return df_proportion_del, df_nobs_del, df_del\n",
    "    else:\n",
    "        return 'input in second argument must be either \"cancelled\" or \"delayed\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in files and concatenate to single dataframe\n",
    "come back to update this to appropriate file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_read_in(folder_name):\n",
    "    \"\"\"Provide absolute file path for files labeled as {month}_2019.csv\"\"\"\n",
    "    combined = pd.DataFrame()\n",
    "    files = ['april', 'march', 'february', 'january', 'december', 'november']\n",
    "    for month in files: \n",
    "        data = pd.read_csv(f\"{folder_name}{month}_2019.csv\")\n",
    "        combined = pd.concat([combined, data])\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Welch's variables\n",
    "\n",
    "### Welch's t-Test\n",
    "\n",
    "Recall that Welch's t-Test is given by  \n",
    "\n",
    "# $ t = \\frac{\\bar{X_1}-\\bar{X_2}}{\\sqrt{\\frac{s_1^2}{N_1} + \\frac{s_2^2}{N_2}}} = \\frac{\\bar{X_1}-\\bar{X_2}}{\\sqrt{se_1^2+se_2^2}}$\n",
    "\n",
    "where $\\bar{X_i}$ , $s_i$, and $N_i$ are the sample mean, sample variance, and sample size, respectively, for sample i.\n",
    "\n",
    "Write a function for calculatying Welch's t-statistic using two samples a, and b. To help, 2 potential samples are defined below.\n",
    "\n",
    "> **Important Note**: While the formula does not indicate it, it is appropriate to take the absolute value of the t-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_t(a, b):\n",
    "    \n",
    "    \"\"\" Calculate Welch's t statistic for two samples. \"\"\"\n",
    "\n",
    "    numerator = a.mean() - b.mean()\n",
    "    \n",
    "    # “ddof = Delta Degrees of Freedom”: the divisor used in the calculation is N - ddof, \n",
    "    #  where N represents the number of elements. By default ddof is zero.\n",
    "    \n",
    "    denominator = np.sqrt(a.var(ddof=1)/a.size + b.var(ddof=1)/b.size)\n",
    "    \n",
    "    return np.abs(numerator/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def welch_df(a, b):\n",
    "    \n",
    "    \"\"\" Calculate the effective degrees of freedom for two samples. \"\"\"\n",
    "    \n",
    "    s1 = a.var(ddof=1) \n",
    "    s2 = b.var(ddof=1)\n",
    "    n1 = a.size\n",
    "    n2 = b.size\n",
    "    \n",
    "    numerator = (s1/n1 + s2/n2)**2\n",
    "    denominator = (s1/ n1)**2/(n1 - 1) + (s2/ n2)**2/(n2 - 1)\n",
    "    \n",
    "    return numerator/denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Cohen's D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(group1, group2):\n",
    "\n",
    "    \"\"\"# Compute Cohen's d.\n",
    "\n",
    "    # group1: Series or NumPy array\n",
    "    # group2: Series or NumPy array\n",
    "\n",
    "    # returns a floating point number\n",
    "\"\"\"\n",
    "    diff = group1.mean() - group2.mean()\n",
    "\n",
    "    n1 = len(group1)\n",
    "    n2 = len(group2)\n",
    "    var1 = group1.var()\n",
    "    var2 = group2.var()\n",
    "\n",
    "    # Calculate the pooled threshold as shown earlier\n",
    "    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n",
    "\n",
    "    # Calculate Cohen's d statistic\n",
    "    d = diff / np.sqrt(pooled_var)\n",
    "\n",
    "    return d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
